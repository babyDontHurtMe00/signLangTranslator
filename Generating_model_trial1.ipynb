{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9a7ef7-ab3c-456b-b9cc-51f935a93930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 #opencv\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4448a8-9d17-477f-98de-769a2b74c128",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./trainingData/A/1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./trainingData/A/1.jpg')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bb6bf-a438-434b-ab68-fcbae53ea686",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39471bfa-15f4-45eb-b7d7-45b95a2169b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray.shape\n",
    "plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1b11c-00dc-4847-a4f4-3b31ad6c5025",
   "metadata": {},
   "source": [
    "## Remove Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47aec8f-8140-4aa0-8cef-78fcbde836a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgremove1(myimage):\n",
    " \n",
    "    # Blur to image to reduce noise\n",
    "    myimage = cv2.GaussianBlur(myimage,(5,5), 0)\n",
    " \n",
    "    # We bin the pixels. Result will be a value 1..5\n",
    "    bins=np.array([0,51,102,153,204,255])\n",
    "    myimage[:,:,:] = np.digitize(myimage[:,:,:],bins,right=True)*51\n",
    " \n",
    "    # Create single channel greyscale for thresholding\n",
    "    myimage_grey = cv2.cvtColor(myimage, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Perform Otsu thresholding and extract the background.\n",
    "    # We use Binary Threshold as we want to create an all white background\n",
    "    ret,background = cv2.threshold(myimage_grey,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    " \n",
    "    # Convert black and white back into 3 channel greyscale\n",
    "    background = cv2.cvtColor(background, cv2.COLOR_GRAY2BGR)\n",
    " \n",
    "    # Perform Otsu thresholding and extract the foreground.\n",
    "    # We use TOZERO_INV as we want to keep some details of the foregorund\n",
    "    ret,foreground = cv2.threshold(myimage_grey,0,255,cv2.THRESH_TOZERO_INV+cv2.THRESH_OTSU)  #Currently foreground is only a mask\n",
    "    foreground = cv2.bitwise_and(myimage,myimage, mask=foreground)  # Update foreground with bitwise_and to extract real foreground\n",
    " \n",
    "    # Combine the background and foreground to obtain our final image\n",
    "    finalimage = background\n",
    "    return finalimage\n",
    "    \n",
    "img2= bgremove1(img)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66137e-ed73-4b6e-a99e-3f86d0a0bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8ed1c-373b-4f81-ae2e-c3e765e77308",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_wvTrans = w2d(img2,'db1',2)\n",
    "plt.imshow(img_wvTrans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e6d18-458e-4993-9438-bce10517aa17",
   "metadata": {},
   "source": [
    "## Creating Dictionary To Iterate Over Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbdda12-2db3-448f-9455-d39efd9d273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToFinalImgs = \"./finalImages/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a0881-5cfd-4981-9cf3-357c4c69cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(pathToFinalImgs):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4445e6-0d00-4218-862c-77af63e7754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655d27d-cb27-46fa-9561-43b536b4fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    img_name = img_dir.split('/')[-1]\n",
    "    img_list = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        img_list.append(entry.path)\n",
    "    img_names_dict[img_name] = img_list\n",
    "img_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a96c39-52e2-468b-886a-db112d990f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#giving nos. to each letter/no.\n",
    "\n",
    "class_dict = {}\n",
    "count = 0\n",
    "for letter_class in img_names_dict.keys():\n",
    "    class_dict[letter_class] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2e99c-03aa-4ddc-8a5e-47c293b8d27e",
   "metadata": {},
   "source": [
    "## Stacking different form of img, and creating X&Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d33d221-6070-45c2-8c92-bab455e175cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "for letter_class, training_files in img_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
    "        \n",
    "        img_har = w2d(img,'db10',2)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        plt.imshow(scalled_img_har)\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[letter_class])     \n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfd9ff-0545-465b-a560-05e00baeb18c",
   "metadata": {},
   "source": [
    "##### len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f740a-83c9-4940-8ad5-b36f4f1cc013",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e6de7-93a6-4137-9ccc-a069d42491bd",
   "metadata": {},
   "source": [
    "## Time to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b2728-1980-4160-8ab9-3c500b37458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a83d3-cebc-48de-8563-1efe53c68c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "# pipe.fit(X_train, y_train)\n",
    "# pipe.score(X_test, y_test)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), svm.SVC(gamma='auto',probability=False))\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de68acd-bb2b-4809-9b1b-4b5d0c721f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test),zero_division=np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fe976-be1a-49b3-9a07-51935f481eb4",
   "metadata": {},
   "source": [
    "## Save Model & Class Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52113ac7-3920-4a12-a071-f7b2368b83bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib\n",
    "import joblib \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(pipe, 'saved_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64c607-8ff1-4ccc-be34-18f28d91319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554c465-d8c2-48e0-b7a4-9d799fd5da83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
